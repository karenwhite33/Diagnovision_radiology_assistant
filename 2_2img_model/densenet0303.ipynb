{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"VZBMk4n6KdkJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741031632564,"user_tz":-60,"elapsed":3966,"user":{"displayName":"Miguel Perez","userId":"02359847243200898040"}},"outputId":"e1fac443-9917-49e2-cc88-1a5f721592f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}],"source":["import torch\n","\n","# Define the device (CPU or GPU)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")"]},{"cell_type":"markdown","source":["## **To train**\n","\n","Model will ask for dfs, val dataloader, train dataloader images processed as 224*224and  normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]).\n","\n"],"metadata":{"id":"z6G7OwKvOswJ"}},{"cell_type":"markdown","source":["**dfs**"],"metadata":{"id":"H2YBvpBbPDrh"}},{"cell_type":"code","source":["# prompt: montar disco de drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BP4DNE2nZgFB","executionInfo":{"status":"ok","timestamp":1741031655030,"user_tz":-60,"elapsed":22465,"user":{"displayName":"Miguel Perez","userId":"02359847243200898040"}},"outputId":"8bb83d24-cd09-4983-8dfe-c41770cb0ddf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","import os\n","\n","# load dfs\n","base_path = \"/content/drive/MyDrive/Diagnovision/filtered_df\"\n","csv_files = [\"train_df.csv\", \"val_df.csv\", \"test_df.csv\"]\n","\n","# Verify if the files exist\n","for file in csv_files:\n","    path = os.path.join(base_path, file)\n","    if os.path.exists(path):\n","        print(f\"{file} found.\")\n","    else:\n","        print(f\"âš  ERROR: {file} Not found.\")"],"metadata":{"id":"UDwO4JNEOyL_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741031656375,"user_tz":-60,"elapsed":1341,"user":{"displayName":"Miguel Perez","userId":"02359847243200898040"}},"outputId":"deb96f37-48f1-4d57-fc48-ebb58da1e0bf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train_df.csv found.\n","val_df.csv found.\n","test_df.csv found.\n"]}]},{"cell_type":"markdown","source":["**tensor folder files**\n","\n","\n","*make sure the code to find the tensors or .pt, scans subfolders since .pt its going to be int the last root subfolder."],"metadata":{"id":"4CVoS0CjRRrk"}},{"cell_type":"code","source":["# Tensors (Preprocessed Images)\n","tensor_save_folder = \"/content/drive/MyDrive/Diagnovision/preprocessed_tensors\""],"metadata":{"id":"di7mTylWRU72"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **dataloaders**"],"metadata":{"id":"EAWRAa-2NjKW"}},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","\n","# Cargar dataset de entrenamiento como memory-mapped tensor\n","train_tensor_path = \"/content/drive/MyDrive/Diagnovision/filtered_df/tensor_df/train_tensor_df.pt\"\n","all_data = torch.load(train_tensor_path, map_location=\"cpu\")\n","\n","class MemoryMappedDataset(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        return self.data[idx]\n","\n","train_dataset = MemoryMappedDataset(all_data)\n","train_dataloader = DataLoader(train_dataset, batch_size=12, shuffle=True)\n","\n","# Cargar dataset de validaciÃ³n como memory-mapped tensor\n","val_tensor_path = \"/content/drive/MyDrive/Diagnovision/filtered_df/tensor_df/val_tensor_df.pt\"\n","all_val_data = torch.load(val_tensor_path, map_location=\"cpu\")\n","\n","val_dataset = MemoryMappedDataset(all_val_data)\n","val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n","\n","print(\"âœ… DataLoaders reconstruidos correctamente.\")\n"],"metadata":{"id":"3MNf8viauAjY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741031856445,"user_tz":-60,"elapsed":199913,"user":{"displayName":"Miguel Perez","userId":"02359847243200898040"}},"outputId":"9adf2e82-baf7-422b-f119-159c7a5a2de1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-5-282d915ebc5d>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  all_data = torch.load(train_tensor_path, map_location=\"cpu\")\n","<ipython-input-5-282d915ebc5d>:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  all_val_data = torch.load(val_tensor_path, map_location=\"cpu\")\n"]},{"output_type":"stream","name":"stdout","text":["âœ… DataLoaders reconstruidos correctamente.\n"]}]},{"cell_type":"markdown","source":["## **densenet 0303**"],"metadata":{"id":"ufu9rvB0uWxl"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","from tqdm import tqdm\n","import os\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","import numpy as np\n","import pandas as pd\n","from torch.utils.data import DataLoader, Dataset\n","\n","# âœ… Configurar dispositivo\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# âœ… Data Augmentation Mejorado\n","train_transform = transforms.Compose([\n","    transforms.RandomRotation(degrees=20),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomAffine(degrees=15, scale=(0.7, 1.3), shear=15),\n","    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.3),\n","    transforms.RandomErasing(p=0.3, scale=(0.02, 0.2)),  # More aggressive\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","val_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","# âœ… Cargar DenseNet121 preentrenado en ImageNet\n","model = models.densenet121(weights=\"IMAGENET1K_V1\")\n","model.classifier = nn.Linear(model.classifier.in_features, 12, bias=True)\n","model.to(device)\n","\n","# âœ… Apply Xavier Initialization (Only for Linear & Conv Layers)\n","for name, param in model.named_parameters():\n","    if 'weight' in name and len(param.shape) > 1:\n","        nn.init.xavier_uniform_(param)\n","\n","# âœ… Load dataset\n","df_labels = pd.read_csv(\"/content/drive/MyDrive/Diagnovision/filtered_df/train_df.csv\")\n","\n","# âœ… Select only label columns\n","label_columns = df_labels.columns.difference(['path_to_image', 'clean_impression'])\n","\n","# âœ… Convert to numeric and clip values (ensuring labels are between 0 and 1)\n","df_labels[label_columns] = df_labels[label_columns].apply(pd.to_numeric, errors='coerce')\n","df_labels[label_columns] = df_labels[label_columns].clip(0, 1)\n","\n","# âœ… Apply balancing function\n","#df_labels = balance_dataset(df_labels)\n","\n","# âœ… Recalculate `pos_weight`\n","label_counts = df_labels[label_columns].sum(axis=0).values.astype(float)\n","pos_weight = torch.tensor((1.0 / (label_counts + 1e-6)), dtype=torch.float32).clip(1,10).to(device)\n","\n","# âœ… Define loss function with `pos_weight`\n","criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n","\n","# âœ… Optimizer and Scheduler\n","optimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n","scheduler = CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-6)\n","\n","# âœ… Training parameters\n","num_epochs = 35\n","best_val_loss = float(\"inf\")\n","best_threshold = 0.5\n","patience = 5\n","early_stop_counter = 0\n","\n","# âœ… Load Checkpoint if available\n","checkpoint_path = \"/content/drive/MyDrive/Diagnovision/modelo_img/best_models/checkpoint_densenet0303.pth\"\n","if os.path.exists(checkpoint_path):\n","    checkpoint = torch.load(checkpoint_path)\n","    model.load_state_dict(checkpoint[\"model_state_dict\"])\n","    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n","    scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n","    epoch = checkpoint[\"epoch\"]\n","    best_val_loss = checkpoint[\"best_val_loss\"]\n","    best_threshold = checkpoint[\"best_threshold\"]\n","    early_stop_counter = checkpoint[\"early_stop_counter\"]\n","    print(f\"Resuming training from epoch {epoch+1}...\")\n","else:\n","    epoch = 0\n","    print(\"Starting training from scratch...\")\n","\n","# âœ… Training Loop\n","for epoch in range(epoch, num_epochs):\n","    model.train()\n","    train_loss = 0.0\n","\n","    for images, labels in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs} (Train)\"):\n","        images, labels = images.to(device), labels.to(device)\n","\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","\n","    # âœ… Validation\n","    model.eval()\n","    val_loss = 0.0\n","    all_labels = []\n","    all_preds = []\n","\n","    with torch.no_grad():\n","        for images, labels in tqdm(val_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs} (Val)\"):\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","\n","            probs = torch.sigmoid(outputs)\n","\n","            # âœ… Dynamic Thresholding\n","            if epoch % 5 == 0:\n","                best_threshold = np.linspace(0.1, 0.9, 9)[np.argmax([f1_score(labels.cpu().numpy(), probs.cpu().numpy() > t, average=\"micro\", zero_division=0) for t in np.linspace(0.1, 0.9, 9)])]\n","\n","            preds = probs > best_threshold\n","            all_labels.extend(labels.cpu().numpy())\n","            all_preds.extend(preds.cpu().numpy())\n","\n","    # âœ… Print Metrics\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss/len(train_dataloader):.6f}, Val Loss: {val_loss/len(val_dataloader):.6f}\")\n","\n","    scheduler.step()\n","\n","    # âœ… Early Stopping\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        early_stop_counter = 0\n","        torch.save(model.state_dict(), \"/content/drive/MyDrive/Diagnovision/modelo_img/best_models/densenet_best0303.pth\")\n","    else:\n","        early_stop_counter += 1\n","        if early_stop_counter >= patience:\n","            print(\"Early stopping!\")\n","            break\n","\n","final_model_path = \"/content/drive/MyDrive/Diagnovision/modelo_img/best_models/densenet_final0303.pth\"\n","torch.save(model.state_dict(), final_model_path)\n","print(f\"âœ… Final model saved at: {final_model_path}\")"],"metadata":{"id":"u2-zidWauWLF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741034250882,"user_tz":-60,"elapsed":2394440,"user":{"displayName":"Miguel Perez","userId":"02359847243200898040"}},"outputId":"1788a56b-5479-4f4f-d8ed-88f93e64139d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30.8M/30.8M [00:00<00:00, 213MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Starting training from scratch...\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1/35 (Train): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2838/2838 [03:42<00:00, 12.77it/s]\n","Epoch 1/35 (Val): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 228/228 [00:19<00:00, 11.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/35, Train Loss: 0.328366, Val Loss: 0.320500\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/35 (Train): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2838/2838 [03:40<00:00, 12.87it/s]\n","Epoch 2/35 (Val): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 228/228 [00:15<00:00, 15.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/35, Train Loss: 0.320227, Val Loss: 0.320994\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/35 (Train): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2838/2838 [03:42<00:00, 12.77it/s]\n","Epoch 3/35 (Val): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 228/228 [00:15<00:00, 15.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/35, Train Loss: 0.319877, Val Loss: 0.320101\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/35 (Train): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2838/2838 [03:40<00:00, 12.85it/s]\n","Epoch 4/35 (Val): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 228/228 [00:15<00:00, 15.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4/35, Train Loss: 0.319616, Val Loss: 0.320511\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/35 (Train): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2838/2838 [03:40<00:00, 12.88it/s]\n","Epoch 5/35 (Val): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 228/228 [00:15<00:00, 15.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5/35, Train Loss: 0.319412, Val Loss: 0.319973\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6/35 (Train): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2838/2838 [03:40<00:00, 12.86it/s]\n","Epoch 6/35 (Val): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 228/228 [00:19<00:00, 11.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6/35, Train Loss: 0.319107, Val Loss: 0.320070\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7/35 (Train): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2838/2838 [03:41<00:00, 12.81it/s]\n","Epoch 7/35 (Val): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 228/228 [00:15<00:00, 15.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7/35, Train Loss: 0.318794, Val Loss: 0.320036\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8/35 (Train): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2838/2838 [03:42<00:00, 12.74it/s]\n","Epoch 8/35 (Val): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 228/228 [00:15<00:00, 15.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8/35, Train Loss: 0.318233, Val Loss: 0.320155\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9/35 (Train): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2838/2838 [03:43<00:00, 12.69it/s]\n","Epoch 9/35 (Val): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 228/228 [00:15<00:00, 15.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9/35, Train Loss: 0.317660, Val Loss: 0.320168\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10/35 (Train): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2838/2838 [03:43<00:00, 12.69it/s]\n","Epoch 10/35 (Val): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 228/228 [00:15<00:00, 14.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/35, Train Loss: 0.317142, Val Loss: 0.320247\n","Early stopping!\n","âœ… Final model saved at: /content/drive/MyDrive/Diagnovision/modelo_img/best_models/densenet_final0303.pth\n"]}]},{"cell_type":"markdown","source":["**evaluacion densenet0303**"],"metadata":{"id":"U8NjJPOQv7kn"}},{"cell_type":"code","source":["import torch\n","import numpy as np\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from tqdm import tqdm\n","\n","# Load the saved model\n","model_path = \"/content/drive/MyDrive/Diagnovision/modelo_img/best_models/densenet_final0303.pth\"\n","\n","# ðŸ“Œ Change to DenseNet121 to match the model used during training\n","model = models.densenet121(weights=\"IMAGENET1K_V1\")\n","model.classifier = nn.Linear(model.classifier.in_features, 12)  # Adjust for 12 classes\n","\n","# Load model weights\n","model.load_state_dict(torch.load(model_path, map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")))\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","model.eval()\n","\n","\n","# Evaluate on validation set\n","all_labels = []\n","all_preds = []\n","all_probs = []\n","\n","with torch.no_grad():\n","    for images, labels in tqdm(val_dataloader, desc=\"Evaluating Model on Validation Set\"):\n","        images, labels = images.to(device), labels.to(device)\n","\n","        # Forward pass\n","        outputs = model(images)\n","        probs = torch.sigmoid(outputs)  # Convert logits to probabilities\n","        preds = (probs > 0.5).float()  # Convert to binary predictions\n","\n","        all_labels.extend(labels.cpu().numpy())\n","        all_preds.extend(preds.cpu().numpy())\n","        all_probs.extend(probs.cpu().numpy())\n","\n","# Convert lists to NumPy arrays\n","all_labels = np.array(all_labels)\n","all_preds = np.array(all_preds)\n","\n","# Compute evaluation metrics\n","accuracy = accuracy_score(all_labels, all_preds)\n","precision_micro = precision_score(all_labels, all_preds, average=\"micro\", zero_division=0)\n","recall_micro = recall_score(all_labels, all_preds, average=\"micro\", zero_division=0)\n","f1_micro = f1_score(all_labels, all_preds, average=\"micro\", zero_division=0)\n","\n","# Print results\n","print(\"\\nðŸ”¹ **FINAL VALIDATION METRICS** ðŸ”¹\")\n","print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n","print(f\"Validation Precision (Micro): {precision_micro:.4f}\")\n","print(f\"Validation Recall (Micro): {recall_micro:.4f}\")\n","print(f\"Validation F1 Score (Micro): {f1_micro:.4f}\")"],"metadata":{"id":"xtVHKc8Nv6r3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741034391840,"user_tz":-60,"elapsed":15744,"user":{"displayName":"Miguel Perez","userId":"02359847243200898040"}},"outputId":"f3eb18e7-c0e8-4b01-acd2-9d2307740bac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-7-397e25669e00>:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(model_path, map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")))\n","Evaluating Model on Validation Set: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 228/228 [00:15<00:00, 14.94it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","ðŸ”¹ **FINAL VALIDATION METRICS** ðŸ”¹\n","Validation Accuracy: 21.41%\n","Validation Precision (Micro): 0.4586\n","Validation Recall (Micro): 0.0074\n","Validation F1 Score (Micro): 0.0147\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["**to eval in TEST**\n","\n","**test dataloader**"],"metadata":{"id":"5cm2X1s0WQhe"}},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","\n","# Cargar el dataset de test como tensor mapeado\n","test_tensor_path = \"/content/drive/MyDrive/Diagnovision/filtered_df/tensor_df/test_tensor_df.pt\"\n","all_test_data = torch.load(test_tensor_path, map_location=\"cpu\")\n","\n","# Crear una clase Dataset para el test\n","class MemoryMappedDataset(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        return self.data[idx]\n","\n","# Crear el DataLoader de test\n","test_dataset = MemoryMappedDataset(all_test_data)\n","test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n","\n","print(\"âœ… DataLoader de test cargado correctamente\")\n"],"metadata":{"id":"HWnbFCeUWQ5X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741034825791,"user_tz":-60,"elapsed":86301,"user":{"displayName":"Miguel Perez","userId":"02359847243200898040"}},"outputId":"f44ab090-3c85-4aa7-acad-83344da48089"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-14-4a06c55d436d>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  all_test_data = torch.load(test_tensor_path, map_location=\"cpu\")\n"]},{"output_type":"stream","name":"stdout","text":["âœ… DataLoader de test cargado correctamente\n"]}]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from tqdm import tqdm\n","import torchvision.models as models\n","import torch.nn as nn\n","\n","# âœ… Changed to a list to contain the model path\n","model_paths = [\"/content/drive/MyDrive/Diagnovision/modelo_img/best_models/densenet_final0303.pth\"]\n","\n","# ðŸ“Œ **Dispositivo (GPU si estÃ¡ disponible)**\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# ðŸ“Œ **Evaluar cada modelo en test**\n","for model_path in model_paths:\n","    print(f\"\\nðŸ”¹ Evaluating Model: {model_path}\")\n","\n","    # **Cargar modelo**\n","    # âœ… Changed to densenet121 to match the model used during training\n","    model = models.densenet121(weights=\"IMAGENET1K_V1\")\n","    model.classifier = nn.Linear(model.classifier.in_features, 12)  # 12 clases\n","\n","    # **Cargar pesos guardados**\n","    model.load_state_dict(torch.load(model_path, map_location=device))\n","    model.to(device)\n","    model.eval()\n","\n","    # **Inicializar mÃ©tricas**\n","    all_labels = []\n","    all_preds = []\n","\n","    # **Evaluar en test**\n","    with torch.no_grad():\n","        for images, labels in tqdm(test_dataloader, desc=\"Evaluating Model on Test Set\"):\n","            images, labels = images.to(device), labels.to(device)\n","\n","            # **Predicciones**\n","            outputs = model(images)\n","            probs = torch.sigmoid(outputs)  # Logits a probabilidades\n","            preds = (probs > 0.5).float()  # Convertir a binario\n","\n","            all_labels.extend(labels.cpu().numpy())\n","            all_preds.extend(preds.cpu().numpy())\n","\n","    # **Convertir a NumPy**\n","    all_labels = np.array(all_labels)\n","    all_preds = np.array(all_preds)\n","\n","    # **Calcular mÃ©tricas**\n","    accuracy = accuracy_score(all_labels, all_preds)\n","    precision_micro = precision_score(all_labels, all_preds, average=\"micro\", zero_division=0)\n","    recall_micro = recall_score(all_labels, all_preds, average=\"micro\", zero_division=0)\n","    f1_micro = f1_score(all_labels, all_preds, average=\"micro\", zero_division=0)\n","\n","    # **Imprimir resultados**\n","    print(\"\\nðŸ”¹ **FINAL TEST METRICS** ðŸ”¹\")\n","    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n","    print(f\"Test Precision (Micro): {precision_micro:.4f}\")\n","    print(f\"Test Recall (Micro): {recall_micro:.4f}\")\n","    print(f\"Test F1 Score (Micro): {f1_micro:.4f}\")"],"metadata":{"id":"HJNsO66xWTOo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741034918807,"user_tz":-60,"elapsed":16307,"user":{"displayName":"Miguel Perez","userId":"02359847243200898040"}},"outputId":"10c94038-0463-4133-bdcc-3c3e8a1d68b7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","ðŸ”¹ Evaluating Model: /content/drive/MyDrive/Diagnovision/modelo_img/best_models/densenet_final0303.pth\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-e61028d18110>:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(model_path, map_location=device))\n","Evaluating Model on Test Set: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 229/229 [00:15<00:00, 14.48it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","ðŸ”¹ **FINAL TEST METRICS** ðŸ”¹\n","Test Accuracy: 21.30%\n","Test Precision (Micro): 0.4486\n","Test Recall (Micro): 0.0075\n","Test F1 Score (Micro): 0.0148\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}]}